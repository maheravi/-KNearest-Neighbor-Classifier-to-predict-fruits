{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked  \n",
       "0         A/5 21171   7.2500     0       0.0  \n",
       "1          PC 17599  71.2833   C85       1.0  \n",
       "2  STON/O2. 3101282   7.9250     0       0.0  \n",
       "3            113803  53.1000  C123       0.0  \n",
       "4            373450   8.0500     0       0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.replace(['female', 'male'], [0, 1])\n",
    "train_data = train_data.replace(['S', 'C', 'Q'], [0, 1, 2])\n",
    "train_data = train_data.fillna(0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "Y_train = train_data[['Survived']]\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_age(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    data[\"Age\"] = scaler.fit_transform(data[\"Age\"].values.reshape(-1,1))\n",
    "    return data\n",
    "train_data = normalize_age(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(7, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(67, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "891/891 [==============================] - 0s 152us/sample - loss: 0.8371 - acc: 0.6397\n",
      "Epoch 2/200\n",
      "891/891 [==============================] - 0s 62us/sample - loss: 0.6232 - acc: 0.6790\n",
      "Epoch 3/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.6035 - acc: 0.6667\n",
      "Epoch 4/200\n",
      "891/891 [==============================] - 0s 55us/sample - loss: 0.5962 - acc: 0.6779\n",
      "Epoch 5/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.5880 - acc: 0.6869\n",
      "Epoch 6/200\n",
      "891/891 [==============================] - 0s 54us/sample - loss: 0.5801 - acc: 0.6768\n",
      "Epoch 7/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.5726 - acc: 0.6813\n",
      "Epoch 8/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.5766 - acc: 0.6689\n",
      "Epoch 9/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.5688 - acc: 0.6857\n",
      "Epoch 10/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.5689 - acc: 0.6779\n",
      "Epoch 11/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.5650 - acc: 0.6734\n",
      "Epoch 12/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.5637 - acc: 0.6824\n",
      "Epoch 13/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.5671 - acc: 0.6813\n",
      "Epoch 14/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.5630 - acc: 0.6700\n",
      "Epoch 15/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.5646 - acc: 0.6835\n",
      "Epoch 16/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.5557 - acc: 0.6779\n",
      "Epoch 17/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.5605 - acc: 0.6745\n",
      "Epoch 18/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.5549 - acc: 0.6891\n",
      "Epoch 19/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.5543 - acc: 0.6891\n",
      "Epoch 20/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.5521 - acc: 0.6790\n",
      "Epoch 21/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.5504 - acc: 0.6902\n",
      "Epoch 22/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.5493 - acc: 0.6925\n",
      "Epoch 23/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.5502 - acc: 0.6958\n",
      "Epoch 24/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.5505 - acc: 0.6925\n",
      "Epoch 25/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.5462 - acc: 0.7048\n",
      "Epoch 26/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.5433 - acc: 0.7082\n",
      "Epoch 27/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.5454 - acc: 0.7160\n",
      "Epoch 28/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.5422 - acc: 0.7138\n",
      "Epoch 29/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.5411 - acc: 0.7116\n",
      "Epoch 30/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.5424 - acc: 0.7250\n",
      "Epoch 31/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.5394 - acc: 0.7284\n",
      "Epoch 32/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.5385 - acc: 0.7273\n",
      "Epoch 33/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.5369 - acc: 0.7284\n",
      "Epoch 34/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.5361 - acc: 0.7250\n",
      "Epoch 35/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.5354 - acc: 0.7340\n",
      "Epoch 36/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.5337 - acc: 0.7329\n",
      "Epoch 37/200\n",
      "891/891 [==============================] - 0s 64us/sample - loss: 0.5383 - acc: 0.7318\n",
      "Epoch 38/200\n",
      "891/891 [==============================] - 0s 66us/sample - loss: 0.5339 - acc: 0.7318\n",
      "Epoch 39/200\n",
      "891/891 [==============================] - 0s 63us/sample - loss: 0.5345 - acc: 0.7262\n",
      "Epoch 40/200\n",
      "891/891 [==============================] - 0s 64us/sample - loss: 0.5331 - acc: 0.7262\n",
      "Epoch 41/200\n",
      "891/891 [==============================] - 0s 67us/sample - loss: 0.5305 - acc: 0.7250\n",
      "Epoch 42/200\n",
      "891/891 [==============================] - 0s 61us/sample - loss: 0.5288 - acc: 0.7374\n",
      "Epoch 43/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.5277 - acc: 0.7318\n",
      "Epoch 44/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.5248 - acc: 0.7374\n",
      "Epoch 45/200\n",
      "891/891 [==============================] - 0s 66us/sample - loss: 0.5285 - acc: 0.7295\n",
      "Epoch 46/200\n",
      "891/891 [==============================] - 0s 66us/sample - loss: 0.5238 - acc: 0.7374\n",
      "Epoch 47/200\n",
      "891/891 [==============================] - 0s 63us/sample - loss: 0.5181 - acc: 0.7419\n",
      "Epoch 48/200\n",
      "891/891 [==============================] - 0s 66us/sample - loss: 0.5185 - acc: 0.7363\n",
      "Epoch 49/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.5183 - acc: 0.7385\n",
      "Epoch 50/200\n",
      "891/891 [==============================] - 0s 65us/sample - loss: 0.5134 - acc: 0.7452\n",
      "Epoch 51/200\n",
      "891/891 [==============================] - 0s 63us/sample - loss: 0.5141 - acc: 0.7419\n",
      "Epoch 52/200\n",
      "891/891 [==============================] - 0s 66us/sample - loss: 0.5105 - acc: 0.7452\n",
      "Epoch 53/200\n",
      "891/891 [==============================] - 0s 62us/sample - loss: 0.5064 - acc: 0.7542\n",
      "Epoch 54/200\n",
      "891/891 [==============================] - 0s 66us/sample - loss: 0.5076 - acc: 0.7520\n",
      "Epoch 55/200\n",
      "891/891 [==============================] - 0s 64us/sample - loss: 0.5036 - acc: 0.7520\n",
      "Epoch 56/200\n",
      "891/891 [==============================] - 0s 63us/sample - loss: 0.4983 - acc: 0.7553\n",
      "Epoch 57/200\n",
      "891/891 [==============================] - 0s 65us/sample - loss: 0.4929 - acc: 0.7587\n",
      "Epoch 58/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4923 - acc: 0.7576\n",
      "Epoch 59/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4881 - acc: 0.7553\n",
      "Epoch 60/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4843 - acc: 0.7587\n",
      "Epoch 61/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4851 - acc: 0.7587\n",
      "Epoch 62/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4846 - acc: 0.7654\n",
      "Epoch 63/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4850 - acc: 0.7755\n",
      "Epoch 64/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4831 - acc: 0.7710\n",
      "Epoch 65/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4756 - acc: 0.7632\n",
      "Epoch 66/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4772 - acc: 0.7722\n",
      "Epoch 67/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4711 - acc: 0.7744\n",
      "Epoch 68/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4690 - acc: 0.7789\n",
      "Epoch 69/200\n",
      "891/891 [==============================] - 0s 66us/sample - loss: 0.4707 - acc: 0.7834\n",
      "Epoch 70/200\n",
      "891/891 [==============================] - 0s 62us/sample - loss: 0.4819 - acc: 0.7699\n",
      "Epoch 71/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4816 - acc: 0.7722\n",
      "Epoch 72/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4694 - acc: 0.7789\n",
      "Epoch 73/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4651 - acc: 0.7823\n",
      "Epoch 74/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4641 - acc: 0.7834\n",
      "Epoch 75/200\n",
      "891/891 [==============================] - 0s 62us/sample - loss: 0.4612 - acc: 0.7834\n",
      "Epoch 76/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4607 - acc: 0.7879\n",
      "Epoch 77/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4637 - acc: 0.7800\n",
      "Epoch 78/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4573 - acc: 0.7868\n",
      "Epoch 79/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4567 - acc: 0.7912\n",
      "Epoch 80/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4578 - acc: 0.7834\n",
      "Epoch 81/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4547 - acc: 0.7935\n",
      "Epoch 82/200\n",
      "891/891 [==============================] - 0s 62us/sample - loss: 0.4556 - acc: 0.7845\n",
      "Epoch 83/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4541 - acc: 0.7980\n",
      "Epoch 84/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4511 - acc: 0.7980\n",
      "Epoch 85/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4634 - acc: 0.7924\n",
      "Epoch 86/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4528 - acc: 0.7879\n",
      "Epoch 87/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4493 - acc: 0.8025\n",
      "Epoch 88/200\n",
      "891/891 [==============================] - 0s 62us/sample - loss: 0.4524 - acc: 0.8047\n",
      "Epoch 89/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4493 - acc: 0.7946\n",
      "Epoch 90/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4462 - acc: 0.7991\n",
      "Epoch 91/200\n",
      "891/891 [==============================] - 0s 63us/sample - loss: 0.4483 - acc: 0.7969\n",
      "Epoch 92/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4467 - acc: 0.8002\n",
      "Epoch 93/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4467 - acc: 0.7957\n",
      "Epoch 94/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4445 - acc: 0.7991\n",
      "Epoch 95/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4456 - acc: 0.7969\n",
      "Epoch 96/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4458 - acc: 0.7935\n",
      "Epoch 97/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4424 - acc: 0.7969\n",
      "Epoch 98/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4417 - acc: 0.8002\n",
      "Epoch 99/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4407 - acc: 0.7969\n",
      "Epoch 100/200\n",
      "891/891 [==============================] - 0s 64us/sample - loss: 0.4398 - acc: 0.8013\n",
      "Epoch 101/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4418 - acc: 0.8036\n",
      "Epoch 102/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4398 - acc: 0.8013\n",
      "Epoch 103/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4386 - acc: 0.7980\n",
      "Epoch 104/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4413 - acc: 0.7969\n",
      "Epoch 105/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4434 - acc: 0.7935\n",
      "Epoch 106/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4400 - acc: 0.8058\n",
      "Epoch 107/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4378 - acc: 0.8047\n",
      "Epoch 108/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4364 - acc: 0.7969\n",
      "Epoch 109/200\n",
      "891/891 [==============================] - 0s 54us/sample - loss: 0.4365 - acc: 0.8058\n",
      "Epoch 110/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4353 - acc: 0.8047\n",
      "Epoch 111/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4363 - acc: 0.8081\n",
      "Epoch 112/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4343 - acc: 0.8013\n",
      "Epoch 113/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4337 - acc: 0.8036\n",
      "Epoch 114/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4345 - acc: 0.8070\n",
      "Epoch 115/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4384 - acc: 0.8002\n",
      "Epoch 116/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4335 - acc: 0.8013\n",
      "Epoch 117/200\n",
      "891/891 [==============================] - 0s 55us/sample - loss: 0.4331 - acc: 0.8070\n",
      "Epoch 118/200\n",
      "891/891 [==============================] - 0s 55us/sample - loss: 0.4332 - acc: 0.8070\n",
      "Epoch 119/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4347 - acc: 0.8025\n",
      "Epoch 120/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4338 - acc: 0.8103\n",
      "Epoch 121/200\n",
      "891/891 [==============================] - 0s 55us/sample - loss: 0.4315 - acc: 0.8036\n",
      "Epoch 122/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4320 - acc: 0.8047\n",
      "Epoch 123/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4305 - acc: 0.8126\n",
      "Epoch 124/200\n",
      "891/891 [==============================] - 0s 62us/sample - loss: 0.4330 - acc: 0.8036\n",
      "Epoch 125/200\n",
      "891/891 [==============================] - 0s 62us/sample - loss: 0.4294 - acc: 0.8002\n",
      "Epoch 126/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4286 - acc: 0.8114\n",
      "Epoch 127/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4289 - acc: 0.8058\n",
      "Epoch 128/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4293 - acc: 0.8058\n",
      "Epoch 129/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4285 - acc: 0.8036\n",
      "Epoch 130/200\n",
      "891/891 [==============================] - 0s 53us/sample - loss: 0.4274 - acc: 0.8070\n",
      "Epoch 131/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4274 - acc: 0.8137\n",
      "Epoch 132/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4297 - acc: 0.8047\n",
      "Epoch 133/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4253 - acc: 0.8092\n",
      "Epoch 134/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4264 - acc: 0.8047\n",
      "Epoch 135/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4256 - acc: 0.8070\n",
      "Epoch 136/200\n",
      "891/891 [==============================] - 0s 63us/sample - loss: 0.4252 - acc: 0.8058\n",
      "Epoch 137/200\n",
      "891/891 [==============================] - 0s 63us/sample - loss: 0.4259 - acc: 0.8058\n",
      "Epoch 138/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4255 - acc: 0.8114\n",
      "Epoch 139/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4246 - acc: 0.8092\n",
      "Epoch 140/200\n",
      "891/891 [==============================] - 0s 55us/sample - loss: 0.4239 - acc: 0.8103\n",
      "Epoch 141/200\n",
      "891/891 [==============================] - 0s 55us/sample - loss: 0.4232 - acc: 0.8058\n",
      "Epoch 142/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4225 - acc: 0.8159\n",
      "Epoch 143/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4221 - acc: 0.8070\n",
      "Epoch 144/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4234 - acc: 0.8137\n",
      "Epoch 145/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4218 - acc: 0.8148\n",
      "Epoch 146/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4223 - acc: 0.8148\n",
      "Epoch 147/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4224 - acc: 0.8036\n",
      "Epoch 148/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4219 - acc: 0.8171\n",
      "Epoch 149/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4219 - acc: 0.8114\n",
      "Epoch 150/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4207 - acc: 0.8114\n",
      "Epoch 151/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4215 - acc: 0.8137\n",
      "Epoch 152/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4210 - acc: 0.8092\n",
      "Epoch 153/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4203 - acc: 0.8171\n",
      "Epoch 154/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4231 - acc: 0.8148\n",
      "Epoch 155/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4231 - acc: 0.8159\n",
      "Epoch 156/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4218 - acc: 0.8025\n",
      "Epoch 157/200\n",
      "891/891 [==============================] - 0s 55us/sample - loss: 0.4195 - acc: 0.8159\n",
      "Epoch 158/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4189 - acc: 0.8126\n",
      "Epoch 159/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4194 - acc: 0.8171\n",
      "Epoch 160/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4187 - acc: 0.8137\n",
      "Epoch 161/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4184 - acc: 0.8148\n",
      "Epoch 162/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4179 - acc: 0.8204\n",
      "Epoch 163/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4182 - acc: 0.8148\n",
      "Epoch 164/200\n",
      "891/891 [==============================] - 0s 62us/sample - loss: 0.4180 - acc: 0.8126\n",
      "Epoch 165/200\n",
      "891/891 [==============================] - 0s 95us/sample - loss: 0.4172 - acc: 0.8193\n",
      "Epoch 166/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4167 - acc: 0.8103\n",
      "Epoch 167/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4184 - acc: 0.8114\n",
      "Epoch 168/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4183 - acc: 0.8182\n",
      "Epoch 169/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4157 - acc: 0.8193\n",
      "Epoch 170/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4175 - acc: 0.8092\n",
      "Epoch 171/200\n",
      "891/891 [==============================] - 0s 55us/sample - loss: 0.4166 - acc: 0.8215\n",
      "Epoch 172/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4161 - acc: 0.8159\n",
      "Epoch 173/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4152 - acc: 0.8182\n",
      "Epoch 174/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4161 - acc: 0.8148\n",
      "Epoch 175/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4154 - acc: 0.8148\n",
      "Epoch 176/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4162 - acc: 0.8182\n",
      "Epoch 177/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4150 - acc: 0.8193\n",
      "Epoch 178/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4143 - acc: 0.8159\n",
      "Epoch 179/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4158 - acc: 0.8159\n",
      "Epoch 180/200\n",
      "891/891 [==============================] - 0s 63us/sample - loss: 0.4133 - acc: 0.8182\n",
      "Epoch 181/200\n",
      "891/891 [==============================] - 0s 61us/sample - loss: 0.4141 - acc: 0.8159\n",
      "Epoch 182/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4133 - acc: 0.8238\n",
      "Epoch 183/200\n",
      "891/891 [==============================] - 0s 62us/sample - loss: 0.4138 - acc: 0.8193\n",
      "Epoch 184/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4125 - acc: 0.8193\n",
      "Epoch 185/200\n",
      "891/891 [==============================] - 0s 55us/sample - loss: 0.4139 - acc: 0.8171\n",
      "Epoch 186/200\n",
      "891/891 [==============================] - 0s 56us/sample - loss: 0.4131 - acc: 0.8204\n",
      "Epoch 187/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4129 - acc: 0.8204\n",
      "Epoch 188/200\n",
      "891/891 [==============================] - 0s 59us/sample - loss: 0.4130 - acc: 0.8215\n",
      "Epoch 189/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4118 - acc: 0.8204\n",
      "Epoch 190/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4115 - acc: 0.8204\n",
      "Epoch 191/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4140 - acc: 0.8204\n",
      "Epoch 192/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4118 - acc: 0.8215\n",
      "Epoch 193/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4139 - acc: 0.8193\n",
      "Epoch 194/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4118 - acc: 0.8249\n",
      "Epoch 195/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4119 - acc: 0.8215\n",
      "Epoch 196/200\n",
      "891/891 [==============================] - 0s 57us/sample - loss: 0.4111 - acc: 0.8204\n",
      "Epoch 197/200\n",
      "891/891 [==============================] - 0s 60us/sample - loss: 0.4109 - acc: 0.8215\n",
      "Epoch 198/200\n",
      "891/891 [==============================] - 0s 62us/sample - loss: 0.4103 - acc: 0.8215\n",
      "Epoch 199/200\n",
      "891/891 [==============================] - 0s 63us/sample - loss: 0.4105 - acc: 0.8215\n",
      "Epoch 200/200\n",
      "891/891 [==============================] - 0s 58us/sample - loss: 0.4098 - acc: 0.8215\n"
     ]
    }
   ],
   "source": [
    "output = model.fit(X_train, Y_train, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f3c5819448>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(output.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data_target = pd.read_csv('gender_submission.csv')\n",
    "\n",
    "test_data = test_data.replace(['female', 'male'], [0, 1])\n",
    "test_data = test_data.replace(['S', 'C', 'Q'], [0, 1, 2])\n",
    "test_data = test_data.fillna(0)\n",
    "\n",
    "X_test = test_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "Y_test = test_data_target[['Survived']]\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 0s 104us/sample - loss: 0.3098 - acc: 0.9139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30979214423295987, 0.9138756]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self, X_train, Y_train):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.number_class = len(np.unique(Y_train))\n",
    "        \n",
    "    def nearestNeighbors(self, X_test):\n",
    "        distance = np.sqrt(np.sum((X_test - self.X_train)**2, axis = 1))\n",
    "        near_neighbor = np.argsort(distance)[0:self.k]\n",
    "        return near_neighbor\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        self.X_test = X_test\n",
    "        y_predict=[]\n",
    "        for i, test in enumerate(self.X_test):\n",
    "            near_neighbor = self.nearestNeighbors(test)\n",
    "            y_predict.append([np.argmax(np.bincount(self.Y_train[near_neighbor]))])\n",
    "        return y_predict\n",
    "    \n",
    "    def evaluate(self, X_test, Y_test):\n",
    "        self.X_test = X_test\n",
    "        self.Y_test = Y_test\n",
    "        y_predict=self.predict(self.X_test)\n",
    "        evaluatation = (y_predict == self.Y_test).sum()/len(self.Y_test)\n",
    "        return evaluatation, y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of KNearestNeighbors classifier is 0.6555023923444976\n"
     ]
    }
   ],
   "source": [
    "Y_train = Y_train.reshape(-1,)\n",
    "knn = KNearestNeighbors(k=5)\n",
    "knn.fit(X_train,Y_train)\n",
    "knn_prediction = knn.predict(X_test)\n",
    "evaluatation, prediction = knn.evaluate(X_test, Y_test)\n",
    "print('The Accuracy of KNearestNeighbors classifier is', evaluatation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineClassifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        self.w = np.matmul(inv(np.matmul(X_train.T, X_train)), np.matmul(X_train.T, Y_train))\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        Y_predic = np.matmul(X_test, self.w)\n",
    "        return Y_predic\n",
    "    \n",
    "    def evaluate(self, X_test, Y_test):\n",
    "        self.X_test = X_test\n",
    "        self.Y_test = Y_test\n",
    "        Y_predic = np.matmul(self.X_test, self.w)\n",
    "        predic = []\n",
    "        for i, pred in enumerate(Y_predic):\n",
    "            if pred > 0.5:\n",
    "                predic.append([1])\n",
    "            elif pred < 0.5:\n",
    "                predic.append([0])\n",
    "        evaluatation = ((predic == self.Y_test).sum())/len(self.Y_test)\n",
    "        return evaluatation, predic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of AdalineClassifier is 0.8971291866028708\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import inv\n",
    "model = AdalineClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "y_predic = model.predict(X_test)\n",
    "evaluatation, prediction = model.evaluate(X_test, Y_test)\n",
    "print('The Accuracy of AdalineClassifier is', evaluatation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Percepton:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train, Y_train):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.number_class = len(np.unique(Y_train))\n",
    "        x_range = np.arange(self.X_train[:, 0].min(), self.X_train[:, 0].max(), 0.01)\n",
    "        y_range = np.arange(self.X_train[:, 1].min(), self.X_train[:, 1].max(), 0.01)\n",
    "        x, y = np.meshgrid(x_range, y_range)\n",
    "\n",
    "        lr = 0.001\n",
    "        self.w = np.random.rand(7, 1)\n",
    "        self.b = np.random.rand(1, 1)\n",
    "        self.Error = []\n",
    "        for i in range(self.X_train.shape[0]):\n",
    "            y_pred = np.matmul(self.X_train[i], self.w) + self.b\n",
    "            e = self.Y_train[i] - y_pred\n",
    "            a = lr * self.X_train[i, :].T * e\n",
    "            \n",
    "            self.w += a.T\n",
    "            self.b += lr * e\n",
    "\n",
    "            Y_pred = np.matmul(self.X_train, self.w) + self.b\n",
    "            error = np.mean(np.abs(self.Y_train - Y_pred))\n",
    "            self.Error.append(error)\n",
    "\n",
    "        return self.Error, self.w, self.b\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        Y_pred = np.matmul(X_test, self.w) + self.b\n",
    "        predic = []\n",
    "        for i, pred in enumerate(Y_pred):\n",
    "            if pred > 0.5:\n",
    "                predic.append([1])\n",
    "            elif pred < 0.5:\n",
    "                predic.append([0])\n",
    "        return predic\n",
    "\n",
    "    def evaluate(self, X_test, Y_test):\n",
    "        Y_pred = np.matmul(X_test, self.w) + self.b\n",
    "        predic = []\n",
    "        for i, pred in enumerate(Y_pred):\n",
    "            if pred > 0.5:\n",
    "                predic.append([1])\n",
    "            elif pred < 0.5:\n",
    "                predic.append([0])\n",
    "        accuracy = (predic == Y_test).sum() / len(Y_test)\n",
    "        error = np.mean(np.abs(Y_test - predic))\n",
    "        return error, accuracy\n",
    "\n",
    "    def pltlost(self):\n",
    "        x = np.arange(0, self.X_train.shape[0])\n",
    "        plt.plot(x, self.Error, marker='o')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Evaluation:  0.4276094276094276 Test Data Accuracy:  0.5723905723905723\n",
      "Test Data Evaluation:  0.3803827751196172 Test Data Accuracy:  0.6196172248803827\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.array(Y_train)\n",
    "Y_train = Y_train.reshape(-1,1)\n",
    "p = Percepton()\n",
    "Error, w, b = p.fit(X_train, Y_train)\n",
    "EvalTest, Accuracy = p.evaluate(X_train, Y_train)\n",
    "print('Test Data Evaluation: ', EvalTest, 'Test Data Accuracy: ', Accuracy)\n",
    "EvalTest, Accuracy = p.evaluate(X_test, Y_test)\n",
    "print('Test Data Evaluation: ', EvalTest, 'Test Data Accuracy: ', Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
